From 862a6bf028be9e5ce96932c5db51f47a85225bd0 Mon Sep 17 00:00:00 2001
From: Han Bing <bing.han@intel.com>
Date: Tue, 5 Jul 2022 09:35:26 +0700
Subject: [PATCH] perf count for v1.6

---
 cmake/config.h.in                                             | 2 +-
 .../image_inference/openvino/openvino_image_inference.cpp     | 4 ++++
 src/postproc/yolo_base.h                                      | 1 +
 3 files changed, 6 insertions(+), 1 deletion(-)

diff --git a/cmake/config.h.in b/cmake/config.h.in
index 2115f23..d922d53 100644
--- a/cmake/config.h.in
+++ b/cmake/config.h.in
@@ -10,5 +10,5 @@
 #cmakedefine ENABLE_VAAPI
 #cmakedefine ENABLE_VPUX
 #cmakedefine ENABLE_ITT
-
+#cmakedefine ENABLE_PERF_CAL
 #endif
diff --git a/inference_backend/image_inference/openvino/openvino_image_inference.cpp b/inference_backend/image_inference/openvino/openvino_image_inference.cpp
index 8897a9e..340d04d 100644
--- a/inference_backend/image_inference/openvino/openvino_image_inference.cpp
+++ b/inference_backend/image_inference/openvino/openvino_image_inference.cpp
@@ -246,6 +246,10 @@ void OpenVINOImageInference::SetCompletionCallback(std::shared_ptr<BatchRequest>
         try {
             ITT_TASK("completion_callback_lambda");
 
+#ifdef ENABLE_PERF_CAL
+            size_t buffer_size = batch_request->buffers.size();
+            GVA_FIXME("model_name: %s, inference size: %ld", const_cast<char*>(model_name.c_str()), buffer_size);
+#endif
             if (code != InferenceEngine::StatusCode::OK) {
                 GVA_ERROR("Inference request failed with code: %d (%s)", code, getErrorMsg(code).c_str());
                 this->handleError(batch_request->buffers);
diff --git a/src/postproc/yolo_base.h b/src/postproc/yolo_base.h
index ee165a4..55f2845 100644
--- a/src/postproc/yolo_base.h
+++ b/src/postproc/yolo_base.h
@@ -14,6 +14,7 @@
 #include <numeric>
 #include <sstream>
 #include <vector>
+#include <limits>
 
 namespace dlstreamer {
 
-- 
2.34.1

